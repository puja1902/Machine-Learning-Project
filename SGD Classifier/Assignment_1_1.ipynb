{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_(1) (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eiDWcM_MC3H"
      },
      "source": [
        "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfe2NTQtLq11"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk5DSPCLxqT-"
      },
      "source": [
        "<font color='red'> Importing packages</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Et8BKIxnsp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpSk3WQBx7TQ"
      },
      "source": [
        "<font color='red'>Creating custom dataset</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMp0oWzx6dv"
      },
      "source": [
        "# please don't change random_state\n",
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
        "# make_classification is used to create custom dataset \n",
        "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8W2fg1cyGdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93c3f32-d617-4c72-efb5-588536ef0bf8"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x99RWCgpqNHw"
      },
      "source": [
        "<font color='red'>Splitting data into train and test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kh4dBfVyJMP"
      },
      "source": [
        "#please don't change random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONY1YiDq7jD"
      },
      "source": [
        "# Standardizing the data.\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(X_train)\n",
        "x_test = scaler.transform(X_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DR_YMBsyOci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d15821c-46e5-4861-f8c9-5bce059fbd37"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4OHswfqjHR"
      },
      "source": [
        "# <font color='red' size=5>SGD classifier</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HpvTwDHyQQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601d0a0a-4335-419b-b2ae-3aa8d843b722"
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYaVyQ2lyXcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc37d8b7-7c24-4777-cda3-4f10d1e80f6c"
      },
      "source": [
        "clf.fit(X=X_train, y=y_train) # fitting our model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
            "Total training time: 0.11 seconds.\n",
            "Convergence after 10 epochs took 0.11 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAfkVI6GyaRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14cb283-de90-4e85-9812-b0e87cdbc507"
      },
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_\n",
        "#clf.coef_ will return the weights\n",
        "#clf.coef_.shape will return the shape of weights\n",
        "#clf.intercept_ will return the intercept term"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
              "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
              "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
              " (1, 15),\n",
              " array([-0.8531383]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-CcGTKgsMrY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1_8bdzitDlM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1.  We will be giving you some functions, please write code in that functions only.\n",
        "\n",
        "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2Y3-FQuJ3z"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
        "\n",
        "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
        "- for each epoch:\n",
        "\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
        "\n",
        "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
        "\n",
        "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "\n",
        "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
        "\n",
        "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
        "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_HgjgS_wKu"
      },
      "source": [
        "<font color='blue'>Initialize weights </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GecwYV9fsKZ9"
      },
      "source": [
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights to zeros array of (1,dim) dimensions\n",
        "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    #initialize bias to zero\n",
        "    w=np.zeros_like(dim)\n",
        "    b=0\n",
        "\n",
        "    return w,b"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7I6uWBRsKc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abc9fa1-51e7-4426-dde3-102e45ee29ac"
      },
      "source": [
        "dim = X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "print('w =',(w))\n",
        "print('b =',str(b))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "b = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MI5SAjP9ofN"
      },
      "source": [
        "<font color='cyan'>Grader function - 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv1llH429wG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7a8d29-7000-4b61-d3f7-34bed54aa34d"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "def grader_weights(w,b):\n",
        "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
        "  return True\n",
        "grader_weights(w,b)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN83oMWy_5rv"
      },
      "source": [
        "<font color='blue'>Compute sigmoid </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPv4NJuxABgs"
      },
      "source": [
        "$sigmoid(z)= 1/(1+exp(-z))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZcOd10ehZ9U"
      },
      "source": [
        "import math"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAfmQF47_Sd6"
      },
      "source": [
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "\n",
        "    return 1 / (1 + math.exp(-z))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YrGDwg3Ae4m"
      },
      "source": [
        "<font color='cyan'>Grader function - 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JASp_NAfK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338d9f49-b5e9-4994-b0aa-fd7e0aedcdbf"
      },
      "source": [
        "def grader_sigmoid(z):\n",
        "  val=sigmoid(z)\n",
        "  assert(val==0.8807970779778823)\n",
        "  return True\n",
        "grader_sigmoid(2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7JXbcrBOFF"
      },
      "source": [
        "<font color='blue'> Compute loss </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEiS22zBVYy"
      },
      "source": [
        "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkLYIaSsso9-"
      },
      "source": [
        "def logloss(y_true, y_pred):\n",
        "    loss = 0\n",
        "    for i in range(len(y_true)):\n",
        "        loss += y_true[i] * math.log10(y_pred[i]) + \\\n",
        "                (1-y_true[i]) * math.log10(1-y_pred[i])\n",
        "    loss = -1 * (1 / len(y_true)) * loss\n",
        "    return loss"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs1BTXVSClBt"
      },
      "source": [
        "<font color='cyan'>Grader function - 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzttjvBFCuQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25800dd7-45a8-4dea-ebe0-1fa4732c07a5"
      },
      "source": [
        "def grader_logloss(true,pred):\n",
        "  loss=logloss(true,pred)\n",
        "  assert(loss==0.07644900402910389)\n",
        "  return True\n",
        "true=[1,1,0,1,0]\n",
        "pred=[0.9,0.8,0.1,0.8,0.2]\n",
        "grader_logloss(true,pred)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQabIadLCBAB"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to  'w' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMxiYKaCQgd"
      },
      "source": [
        "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gruY5nqJWghh"
      },
      "source": [
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "\n",
        "    dw =x*(y-sigmoid(np.dot(w,x)+b)) - ((alpha*w)/N)\n",
        "    return dw"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUFLNqL_GER9"
      },
      "source": [
        "<font color='cyan'>Grader function - 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI3xD8ctGEnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e366a5a5-ff5d-46ae-9cea-90083a822d52"
      },
      "source": [
        "def grader_dw(x,y,w,b,alpha,N):\n",
        "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
        "  assert(np.sum(grad_dw)==2.613689585)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8g84_GI62n"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to 'b' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvTYZzZJJ_N"
      },
      "source": [
        "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nUf2ft4EZp8"
      },
      "source": [
        " def gradient_db(x,y,w,b):\n",
        "     '''In this function, we will compute gradient w.r.to b '''\n",
        "     db = y - (sigmoid(np.dot(w, x) + b))\n",
        "     return db"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbcBzufVG6qk"
      },
      "source": [
        "<font color='cyan'>Grader function - 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfFDKmscG5qZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "762128aa-06ce-4639-80ac-b6dd6303aba9"
      },
      "source": [
        "def grader_db(x,y,w,b):\n",
        "  grad_db=gradient_db(x,y,w,b)\n",
        "  assert(grad_db==-0.5)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_db(grad_x,grad_y,grad_w,grad_b)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCK0jY_EOvyU"
      },
      "source": [
        "<font color='blue'> Implementing logistic regression</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOPad2Ib4qkj"
      },
      "source": [
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
        "    ''' In this function, we will implement logistic regression'''\n",
        "    #Here eta0 is learning rate\n",
        "    #implement the code as follows\n",
        "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
        "    w, b = initialize_weights(X_train[0])\n",
        "    # for every epoch\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    for epoch in range(epochs):\n",
        "        # for every data point(X_train,y_train)\n",
        "        for x, y in zip(X_train, y_train):\n",
        "             #compute gradient w.r.to w (call the gradient_dw() function)\n",
        "            dw = gradient_dw(x, y, w, b, alpha, len(X_train))\n",
        "            #compute gradient w.r.to b (call the gradient_db() function)\n",
        "            db = gradient_db(x, y, w, b)\n",
        "            #update w, b\n",
        "            w = w + eta0 * dw\n",
        "            b = b + eta0 * db\n",
        "        \n",
        "        # predict the output of x_train[for all data points in X_train] using w,b\n",
        "        y_pred = [sigmoid(np.dot(w, x) + b) for x in X_train]\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "        train1 = round(logloss(y_train, y_pred),6)\n",
        "        train_loss.append(train1)\n",
        "        # store all the train loss values in a list\n",
        "        # predict the output of x_test[for all data points in X_test] using w,b\n",
        "        y_pred_test = [sigmoid(np.dot(w, x) + b) for x in X_test]\n",
        "        \n",
        "        print(f\"EPOCH: {epoch} Train Loss: {round(logloss(y_train, y_pred),6)} Test Loss: {round(logloss(y_test, y_pred_test),6)}\")\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "        tests = round(logloss(y_test, y_pred_test),6)\n",
        "        # test_loss.append(logloss(y_test, y_pred_test))\n",
        "        test_loss.append(tests)\n",
        "        # you can also compare previous loss and current loss if the loss is not updating then stop the process and return w,b\n",
        "\n",
        "    return w,b, train_loss, test_loss"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUquz7LFEZ6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d139a6e7-3ddc-4776-d324-60d2481e4602"
      },
      "source": [
        "alpha=0.0001\n",
        "eta0=0.0001\n",
        "N=len(X_train)\n",
        "epochs = 15\n",
        "w,b, train_loss, test_loss = train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0 Train Loss: 0.175457 Test Loss: 0.175955\n",
            "EPOCH: 1 Train Loss: 0.168672 Test Loss: 0.169399\n",
            "EPOCH: 2 Train Loss: 0.166392 Test Loss: 0.167206\n",
            "EPOCH: 3 Train Loss: 0.165368 Test Loss: 0.166217\n",
            "EPOCH: 4 Train Loss: 0.164857 Test Loss: 0.16572\n",
            "EPOCH: 5 Train Loss: 0.164588 Test Loss: 0.165456\n",
            "EPOCH: 6 Train Loss: 0.164443 Test Loss: 0.165311\n",
            "EPOCH: 7 Train Loss: 0.164363 Test Loss: 0.165231\n",
            "EPOCH: 8 Train Loss: 0.164318 Test Loss: 0.165186\n",
            "EPOCH: 9 Train Loss: 0.164293 Test Loss: 0.16516\n",
            "EPOCH: 10 Train Loss: 0.164279 Test Loss: 0.165146\n",
            "EPOCH: 11 Train Loss: 0.164271 Test Loss: 0.165137\n",
            "EPOCH: 12 Train Loss: 0.164266 Test Loss: 0.165133\n",
            "EPOCH: 13 Train Loss: 0.164264 Test Loss: 0.16513\n",
            "EPOCH: 14 Train Loss: 0.164262 Test Loss: 0.165128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Zf_wPARlwY"
      },
      "source": [
        "<font color='red'>Goal of assignment</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3eF_VSPSH2z"
      },
      "source": [
        "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA1k4BgyARgw",
        "outputId": "51923580-4410-4a7b-9beb-0734b0ee5d0a"
      },
      "source": [
        "print(w)\n",
        "print(\"------------------------------------------------------------------------------------------\")\n",
        "print(b)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-4.28180804e-01  1.92534041e-01 -1.47858302e-01  3.38107274e-01\n",
            " -2.19042252e-01  5.68820894e-01 -4.45207209e-01 -9.03368967e-02\n",
            "  2.20891208e-01  1.72850106e-01  1.97896252e-01  1.12215163e-04\n",
            " -8.04841355e-02  3.39015970e-01  2.27804817e-02]\n",
            "------------------------------------------------------------------------------------------\n",
            "-0.88207772553045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLwO7DzG4ZGe",
        "outputId": "7298c296-5b3e-42b5-8b54-a998a77e526d"
      },
      "source": [
        "w-clf.coef_, b-clf.intercept_\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.00481389,  0.00705839,  0.00073206, -0.0033368 , -0.01085555,\n",
              "          0.00865511,  0.00721762,  0.00375123,  0.01161801, -0.00799116,\n",
              "          0.00084435, -0.00410694, -0.00088044,  0.00048795,  0.00011327]]),\n",
              " array([-0.02893943]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230YbSgNSUrQ"
      },
      "source": [
        "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
        "\n",
        "* epoch number on X-axis\n",
        "* loss on Y-axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "VO3hhnqsBMLE",
        "outputId": "80c3b20d-324f-4b96-f0be-6eecff887bcc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch = []                                                                  \n",
        "for i in range(0,15):\n",
        "  epoch.append(i)\n",
        "\n",
        "plt.plot(epoch, train_loss, label='epoch vs train_loss')\n",
        "plt.plot(epoch, test_loss, label='epoch vs test_loss')\n",
        "\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"epoch number\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"Plot epoch number vs train , test loss\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhU5fXA8e/JZIVsrCFhEQQEggSQRSuyuYF1b1GktkBdqLa21rYqba17q622WBWrVlsXRPDnVrW4oCWAUstmQNkUASHsexJIyHZ+f9w7YUgmyUySyWSS83meeebe973Lmclkztz3vfe+oqoYY4wxgYoKdwDGGGMiiyUOY4wxQbHEYYwxJiiWOIwxxgTFEocxxpigWOIwxhgTFEsczZyIZIvIdeGOo66aavwiMkZEcsMdR2MQkXdFZEq446gPEekuIioi0eGOpTmwxNEMiMgWESkUkQIR2S0iz4lIYpDbsH+sZsj9m/aqzzZU9QJVfb6hYvJqyOTbVH9gNFeWOJqPi1U1ETgNGArcEeZ4TIDCmazth4KpC0sczYyqbgfeBU6tXCciUSJyh4h8IyJ7ROQFEUlxqxe5z4fcI5dvVbP+dBH5WkT2i8grItLWrfMesUwTkR0islNEfuWzbpyIPOLW7XCn43zqLxWRHBHJc7c/3mfXJ4nIJyKSLyIfiEh7f6/d+wtWRH7pvr6dIvJDn/oTfpWKyFQR+dhnXkXkxyLylbuv+0Skp4gsceN6RURiK+3zNyKyzz3qu7rS631YRLa6R4FPikhCpThvF5FdwD8rbTNORA6JyKk+ZR3co8qOItJeRN5xlzkgIotFpMr/soh4/6ar3L/pRH/7FpE27vb2ishBd7qLv/fN+565r+2giGwWkQv8/T1qIiKtcT6nGW5sBSKSUctnLF5EZrnlh0RkmYikicjvgZHA4+52Hg9g/xki8pb7/m0Uket96oaLyHL3b75bRP5S0/6Dfe3NgSWOZkZEugLfBj7zUz3VfYwFTgYSAe8/2Sj3OVVVE1X1v37W/ylwGTAayAAOAjMrLTMW6A2cD9wuIue65b8FzgAGAQOB4bhHRSIyHHgBuBVIdWPZ4rPN7wE/BDoCscCvqF4nIAXoDFwLzBSRNjUsX9k4YIgb623A08D3ga44yXhSpX21d/c1BXhaRPq4dQ8Cp7ivt5e7zJ2V1m0LnARM8w1AVY8Br1fa15XAQlXdA/wSyAU6AGnAb4Aq9w5SVe/fdKD7N51bzb6jcJLXSUA3oJDjnwt/Tgc2uK/9T8CzIiI1LF+Fqh4BLgB2uLElquoOav6MTcH523YF2gE3AIWq+ltgMXCTu52bAghhDs57mAFMAP4gIme7dX8F/qqqyUBP4JWa9h/M6242VNUeEf7A+ZItAA4B3wBPAAluXTZwnTv9EfBjn/X6ACVANNAd58snuob9rAPO8ZlP97N+X5/6PwHPutNfA9/2qRsHbHGnnwJmVLPPbOAOn/kfA+9Vs+wYnH/kaJ+yPcAZld8Ld34q8LHPvAIjfOZXALf7zP8ZeMRnX6VAa5/6V4DfAQIcAXr61H0L2OyzbjEQX8N7fS7wtc/8J8Bkd/pe4F9ArwA+G+q7XID7HgQcrPQ38H6GpgIbfepaufvoVIfP7RggN4jP2DXAEiCrms/JdTXsy/v5jMb54i8DknzqHwCec6cXAfcA7Stto9r9t7SHHXE0H5epaqqqnqSqP1ZVf7+EMnASi9c3OP9IgR5unwS84R6mH8L5Jy+rtP62StvPqGHf3rquOImlOrt8po/iHClVZ7+qlgaxfGW7faYL/cz7buugOr+cvbyvqQPOF+oKn/fqPbfca6+qFtUQxwKglYicLiLdcb7M33DrHgI2Ah+IyCYRmR7oi/O3bxFpJSJPidOEmYfzxZkqIp5q1q/4e6jqUXcyqJMxalDTZ+xF4H1gjjjNnX8SkZg67CMDOKCq+T5l3+AcFYJzpHoKsN5tjrrILW+o/Uc8Sxwtyw6cf0yvbji/mnfjp6nDj23ABW6C8j7i1elX8epaafs7ati3t24bTpNAqB3B+UL36lTP7bVx2+q9vK9pH06S6e/zPqWoc/KCV43vt6qW4RzBTHIf73i/6FQ1X1V/qaonA5cAvxCRc4KIu/K+f4lz9Hm6Os0z3iauoJqf6sDfe1DtZ0xVS1T1HlXNBM4ELgIm17Ct6uwA2opIkk9ZN2A7gKp+paqTcJpG/wi8KiKta9l/i2KJo2V5GbhFRHqIc7ruH4C57i/0vUA5Tt9HdZ4Efi8iJ0FFh+2llZb5nfsLtj9Ov4S3Xf1l4A53nfY47f2z3LpngR+KyDlu52hnEenbAK+3shzgO258vXB+WdbXPSISKyIjcb5I/k9Vy4G/AzNEpCOA+5rGBbnt2cBE4Gp3GndbF4lIL7df4TDOL/Lyaraxm5r/pgBJOInukNsRfVeQcVZLnFPDn6shtnZy/AQNqOEzJiJjRWSAeySUh9OEVe6zrdpeJwCqug2nyekBt8M7C+ezMMvdz/dFpIP7dzzkrlZey/5bFEscLcs/cA63FwGbgSKczkhvk8PvgU/cZoIz/Kz/V+AtnCaSfOBTnI5SXwtxmlE+Ah5W1Q/c8vuB5cBq4HNgpVuGqi7FSTIzcL4IF3Li0UlDmYHTvr8beB54qZ7b24XTebvD3dYNqrrerbsd53341G3++RDnV33AVPV/OEdJGThnIHn1drdXAPwXeEJVF1SzmbuB592/6ZXVLPMIkIBzpPQpTrNaQ+mK0z9ThftevQxscuPLoObPWCfgVZwv7XU4n5MX3bq/AhPEOdPr0QDimoTT77EDpwnwLlX90K0bD6wRkQJ3u1e5Tb817b9FEbfTx5h6cdvhNwMxlfoYTAslzqnLq3A6k0vCHY9pOHbxjzEmJFS1GOgX7jhMw7OmKmOMMUGxpipjjDFBsSMOY4wxQWkRfRzt27fX7t2712ndI0eO0Lp169oXbCIiKV6LNXQiKd5IihUiK976xrpixYp9qtqhSkW4L11vjMeQIUO0rhYsWFDndcMhkuK1WEMnkuKNpFhVIyve+sYKLFe75Ygxxpj6ssRhjDEmKJY4jDHGBKVFdI4bY6oqKSkhNzeXoqKabtIbeikpKaxbty6sMQQjkuINNNb4+Hi6dOlCTExgN/sNaeIQZxS3vwIe4BlVfbBS/Sic++Rk4dwP5lW3fCzOfYW8+rr1b7o3drsfuALn5m5/U9VA7k1jjPGRm5tLUlIS3bt3J8hxmBpUfn4+SUlJtS/YRERSvIHEqqrs37+f3NxcevToEdB2Q5Y43DtIzgTOwxlpa5mIvKWqa30W24ozMMwJI7qpc8O2Qe522uKOPeBWT8W5cVpfVS333n3UGBOcoqKisCcNE34iQrt27di7d2/A64TyiGM4zkhhmwBEZA5wKVCROFR1i1tX062JJwDv6vEBY24EvqfOLY9RZyhNY0wdWNIwEPznIJSJozMnjgaXS9VbcAfiKuAvPvM9gYkicjnOGBI/U9WvKq8kItNwx3JOS0sjOzs76B133L2QtkcOEvya4VNQUFCn1xoOFmvoBBJvSkoK+fn5NS7TGMrKyppEHIGKpHiDibWoqCjgz3iT7hwXkXRgAM5wjV5xQJGqDhWR7+CMMTGy8rqq+jTwNMDQoUN1zJgxwQcw91kK9ywl4ZpHgl83TLKzs6nTaw0DizV0Aol33bp1TaKtPpL6DCCy4g0m1vj4eAYPHhzQsqE8HXc7Jw4j2sUtC8aVwBt64r38c4HX3ek3cDrWQyN9IAlFu6DwUO3LGmOalOzsbC666KLaF6zH9pcsWRL0esuXL+dnP/tZnfaZmNhQQ7vXTygTxzKgtztMaSxOk9NbQW5jEs4IYb7eBMa606OBL+sVZU3SBznPuz4P2S6MMZGppsRRWlr9WGZDhw7l0Ucj+0TQkDVVqWqpiNyE08zkAf6hqmtE5F6c+5+8JSLDcI4a2gAXi8g9qtofKkaU64ozPKOvB4GXROQWnKEzrwvVayB9oPO8cxX0qNIaZkyzcc/ba1i7I69Bt5mZkcxdF/evcZlZs2YxY8YMysrKOP3003niiSfweDwkJiZy/fXX88EHH9CpUyfmzJlDhw4dyMnJ4YYbbuDo0aP07NmTf/zjH7Rp04aNGzdyww03sHfvXjweD//3f/8HOH09EyZM4IsvvmDIkCHMmjXrhI7g9evXM3nyZJYuXQrAli1buPjii/n888+ZPn06b731FtHR0Zx//vk8/PDDFett2bKFJ598Eo/Hw6xZs3jsscd49tlniY+P57PPPmPEiBFcddVV3HzzzRQVFZGQkMA///lP+vTpQ3Z2Ng8//DDvvPMOd999N1u3bmXTpk1s3bqVn//85wEdjagqt912G++++y4iwh133MHEiRPZuXMnEydOJC8vj9LSUv785z9z7rnncu2117J8+XJEhGuuuYZbbrmlLn/SCiHt41DVecC8SmV3+kwvw2nC8rfuFpwO9srlh4ALGzTQ6iR2oCiuHfE7cxpld8a0JOvWrWPu3LnMnz+ftm3b8uMf/5iXXnqJyZMnc+TIEYYOHcqMGTO49957ueeee3j88ceZPHkyjz32GKNHj+bOO+/knnvu4ZFHHuHqq69m+vTpXH755RQVFVFeXs62bdv47LPPWLNmDRkZGYwYMYJPPvmEs846qyKGvn37UlxczObNm+nRowdz585l4sSJ7N+/nzfeeIP169cjIhw6dGJzdffu3bnhhhtITEzkV79yriZ49tlnyc3NZcmSJXg8HvLy8li8eDHR0dF8+OGH/OY3v+G1116r8j6sX7+eBQsWkJ+fT58+fbjxxhtrvRDv9ddfJycnh1WrVrFv3z6GDRvGqFGjmD17NuPGjeO3v/0tZWVl7N69m5ycHLZv384XX3wBUOW11EWT7hxvCgoSexK/c1W4wzAmpGo7MgiFjz76iBUrVjBmzBiioqIoLCykY0fnsqyoqCgmTpwIwPe//32+853vcPjwYQ4dOsTo0aMBmDJlCldccQX5+fls376dyy+/HHA6eb2GDx9Oly7Ob9NBgwaxZcuWExIHwJVXXsncuXOZPn06c+fOZe7cuaSkpBAfH8+1117LRRddFHBfyRVXXIHH4wHg8OHDTJkyha+++goRoaTE/7DrF154IXFxccTFxdGxY0d2795dEXN1Pv74YyZNmoTH4yEtLY3Ro0ezbNkyhg0bxjXXXENJSQmXXXYZPXv2JCEhgU2bNvHTn/6UCy+8kPPPPz+g11ITu1dVLfKTesK+r+BYQbhDMaZZUVWmTJnCJ598Qk5ODhs2bODuu+/2u2xdrzeJi4urmPZ4PH77HiZOnMgrr7zCl19+iYjQu3dvoqOjWbp0KRMmTOCdd95h/PjxAe3Pd+yL3/3ud4wdO5YvvviCt99+u9pbuwQSY6BGjRrFokWL6Ny5M1OnTmX27Nm0adOGVatWMWbMGJ588kmuu67+rfuWOGpQXFrOrrgegMLuL8IdjjHNyjnnnMOrr75accXygQMH+OabbwAoLy/n1VdfBWD27NmcddZZpKSk0KZNGxYvXgzAiy++yOjRo0lKSqJLly68+eabABw7doyjR4/62aN/PXv2xOPxcN9991Uc5RQUFHD48GG+/e1vM2PGDFatqtrqkJSUVOM1EocPH6ZzZ6e1/bnnngs4nkCMHDmSuXPnUlZWxt69e1m0aBHDhw/nm2++IS0tjeuvv57rrruuoimrvLyc7373u9x///2sXLmy3vu3pqoaTPnHUsr3d+Fb4HSQdzsj3CEZ02xkZmZy//33c9lllwEQExPDzJkzOemkk2jdujVLly7l/vvvp2PHjsydOxeA559/vqJz/OSTT+af//wn4CSRH/3oR9x5553ExMRUdI4HauLEidx6661s3rwZcK5/uPTSSykqKkJV+ctf/lJlnYsvvpgJEybwr3/9i8cee6xK/W233caUKVO4//77ufDChu2Wvfzyy/nvf//LwIEDERH+9Kc/0alTJ55//nkeeughYmJiSExM5IknnmD79u388Ic/pLzcuUHHAw88UO/9izPIU/M2dOhQXb58edDr3fP2Gl76dDMbUm9Bep0Ll/8tBNE1rEi6UM1iDZ1ALwDs169f4wRUA38XqSUmJlJQ0DSbh5vrBYD+Pg8iskJVh1Ze1pqqapCZnkxxmXC03anOEYcxxhhrqqpJ/4wUALYn9OaUbQuhpBBiEsIclTHNX1M92mgM+/fv55xzzqlS/tFHH9GuXbswRFSVJY4a9OqYiEfg8/IenKJlsHstdBkS7rCMMc1Yu3btyMlp2teOWVNVDWKjo+iSFMXiAvc6RLsQ0BhjLHHUpltSFIt3x6MJbSxxGGMMljhq1S05iv1HSyjuMMA6yI0xBkscteqW5LxFu1r1cfo4SovDHJExxoSXJY5adEt23qJ1cjKUl8DedWGOyBgTiKY6Hgc4d9edPXt2rdsPZfz1YYmjFgnRwkntWrHkiHvTsR3Wz2GMCX3iaMrsdNwA9M9IZtH2cohLtn4O0zy9O73hByzrNAAueLDGRZrTeBx9+/blhhtuYOvWrQA88sgjjBgxgoULF3LzzTcDzs0aFy1axPTp01m3bh2DBg1iypQptY6PceDAAa655ho2bdpEq1atePrpp8nKyvK77YKCgooxOYqLi3nqqacYObJhxxOyI44A9M9IYcuBIko72hXkxjQU3/E4cnJy8Hg8vPTSSwAV43GsWbOG0aNHc8899wAwefJk/vjHP7J69WoGDBhQUX711Vfzk5/8hFWrVrFkyRLS09MB+Oyzz3jkkUdYu3YtmzZt4pNPPjkhBt/xOIAq43GsWbOG1atXc8cdd5ywnnc8jltuuYWcnBxGjhzJzTffzC233MKyZct47bXXKu5C+/DDDzNz5kxycnJYvHgxCQkJPPjgg4wcOZKcnJyABlW66667GDx4MKtXr+YPf/gDkydPrnbb3jE5cnJyWLJkCYMGDarrn6hadsQRgMz0ZAD2JfWj05cvQVkpeOytM81ILUcGodDcxuP48MMPWbt2bcV8Xl4eBQUFjBgxgl/84hdcffXVfOc736l1rA1/Pv7444pBoM4++2z2799PXl6e3237jslx3nnnMWLEiKD3Vxs74ghA/wwncWyIOhlKi2Bf6IY5N6alaG7jcZSXl/Ppp5+Sk5NTMepeYmIi06dP55lnnqGwsJARI0awfv36Or0Wf/xt23dMjhtvvJEXXnihwfbnZYkjAB2S4mifGMvSoq5OgV0IaEy9NbfxOM4///wTbq/uvW3I119/zYABA7j99tsZNmwY69evr3Usj8pGjhxZ0YyXnZ1N+/btSU5O9rtt3zE5Jk+e3CDjb1RmiSMAIkJmRgoL96VATCvr5zCmAfiOx5GVlcV5553Hzp07ASrG4zj11FP5z3/+w5133gk443HceuutZGVlkZOTU1H+4osv8uijj5KVlcWZZ57Jrl27gopl4sSJzJo1iyuvvBJwbkd+0UUXkZWVxVlnnVXteBxvvPEGgwYNYvHixTz66KMsX76crKwsMjMzefLJJwGnk/zUU08lKyuLmJgYLrjgArKysvB4PAwcOJAZM2bUGt/dd9/NihUryMrKYvr06Tz//PPVbjs7O5uBAwcyePBgXn/99YrO8walqs3+MWTIEK2rBQsWqKrqA/PWaa/f/FvL/n6u6rPj6ry9UPPGGwks1tAJJN61a9eGPpAA5OXlVSlr3bp1GCIJjL94m6pgYvX3eQCWq5/vVDviCFD/jGRKypSDKZmwczW4o2kZY0xLY6cGBSjT7SD/OroX7UqOwIGvoX3vMEdlTPPUksbjeP/997n99ttPKOvRowdvvPFGmCKqnSWOAHVv15pWsR5WHOvGcHCuILfEYSKcqtb5jCXTMMaNG8e4cePCGoMGOYS4NVUFyBMl9O2UxKJDbcETZ2dWmYgXHx/P/v37g/7SMM2LqrJ///4Trn+pTUiPOERkPPBXwAM8o6oPVqofBTwCZAFXqeqrbvlYwPdUg75u/Zs+6z4KXKOqiaF8Db76Z6Tw5mfb0c79ETuzykS4Ll26kJubW3E6bLgUFRUF9aUVbpEUb6CxxsfHB3VhYsgSh4h4gJnAeUAusExE3lLVtT6LbQWmAr/yXVdVFwCD3O20BTYCH/hseyjQJlSxVyczI5kXP/2GgrankvTVv0AV7DDfRKiYmBh69OgR7jDIzs5m8ODB4Q4jYJEUb6hiDWVT1XBgo6puUtViYA5wqe8CqrpFVVcDNZ2iNAF4V1WPQkVCegi4LTRhV897BfmW2F5w7DAc3NzYIRhjTNiFsqmqM7DNZz4XOL0O27kK8L365ibgLVXdWVOnnohMA6YBpKWlkZ2dXYddO2d3eNctLlOiBN7dFssAYM2HL7O3Y8PfB6Y+fONt6izW0ImkeCMpVoiseEMVa5M+q0pE0oEBwPvufAZwBTCmtnVV9WngaYChQ4fqmDG1ruJXdnY2vuv2Xr2Ija2yICqa/m1LoI7bDZXK8TZlFmvoRFK8kRQrRFa8oYo1lE1V24GuPvNd3LJgXAm8oaol7vxgoBewUUS2AK1EZGN9Aw1GZkYyq3cWQcd+dusRY0yLFMrEsQzoLSI9RCQWp8nprSC3MQl42Tujqv9W1U6q2l1VuwNHVbVXg0UcgP4ZyezKK6KoQ5aTOOxURmNMCxOyxKGqpTj9Ee8D64BXVHWNiNwrIpcAiMgwEcnFaX56SkTWeNcXke44RywLQxVjXXjH5siN7w1H98Ph3DBHZIwxjSukfRyqOg+YV6nsTp/pZThNWP7W3YLTwV7T9hvtGg4v761HVpd1pxc4Rx2pXWtcxxhjmhO7cjxIqa1i6ZyawMf5nUCirJ/DGNPiWOKog8yMZFbtOgbt+1jiMMa0OJY46iAzPZlN+45Q2inLEocxpsWxxFEH/TOSUYWdrfpAwS7ID260MWOMiWSWOOrA20G+Vt37/NhRhzGmBbHEUQedUxNISYhhyZHOgFjiMMa0KJY46kBE6J+RTM7uEmjXyxKHMaZFscRRR5npyazflU95pyxnNEBjjGkhLHHUUf/OyRwrLWd/cj/Iy4Uj+8IdkjHGNApLHHWUmZ4CwAY52Smw5ipjTAthiaOOenZoTWx0FP8rdO+KYonDGNNCWOKoo2hPFH07JbFyL9CmuyUOY0yLYYmjHvpnJLNmRx6aPhB2Wge5MaZlsMRRD5npyRw6WkJ+an84uAUKD4Y7JGOMCTlLHPWQmeF0kG+M7ukU7Po8jNEYY0zjsMRRD307JSECy491cwqsn8MY0wJY4qiH1nHR9GjfmuV7oyC5iyUOY0yLYImjnjLTk1m7Mw/SB9oV5MaYFsESRz31z0gh92AhRe1Phf0b4Vh+uEMyxpiQssRRT95brG+O7QUo7PoivAEZY0yIWeKop8x0J3F8VmId5MaYlsESRz11SIqjY1Icyw/EQ2KaXQhojGn2LHE0gP4Zyazd4XaQ2xGHMaaZs8TRADIzktm4p4DSjgNg73ooPhrukIwxJmQscTSA/hkplJYr2xP6gJbDnrXhDskYY0ImpIlDRMaLyAYR2Sgi0/3UjxKRlSJSKiITfMrHikiOz6NIRC5z615yt/mFiPxDRGJC+RoC4e0gX13e3Smwfg5jTDMWssQhIh5gJnABkAlMEpHMSottBaYCs30LVXWBqg5S1UHA2cBR4AO3+iWgLzAASACuC9VrCFS3tq1IjItm2YFWkNDWLgQ0xjRr0SHc9nBgo6puAhCROcClQEU7jqpucevKa9jOBOBdVT3qrjPPWyEiS4EuDR55kKKihH7pSazZmW8d5MaYZi+UiaMzsM1nPhc4vQ7buQr4S+VCt4nqB8DN/lYSkWnANIC0tDSys7PrsGsoKCgIaN2U8mMs3l7KNye3oevuxSz+z3w0qvFb0QKNtymwWEMnkuKNpFghsuINVayhTBz1JiLpOE1S7/upfgJYpKqL/a2rqk8DTwMMHTpUx4wZU6cYsrOzCWTdPa238eHW1cT3O4+oba8zum8HyBhUp33WR6DxNgUWa+hEUryRFCtEVryhijWUnePbga4+813csmBcCbyhqiW+hSJyF9AB+EW9ImxA3luPrOFkp8A6yI0xzVQoE8cyoLeI9BCRWJwmp7eC3MYk4GXfAhG5DhgHTFLVmvpGGtUpaUnEeIRlh1MgLsX6OYwxzVbIEoeqlgI34TQzrQNeUdU1InKviFwCICLDRCQXuAJ4SkTWeNcXke44RywLK236SSAN+K97qu6doXoNwYiNjqJXxyTW7syH9CxLHMaYZiukfRzuGVDzKpXd6TO9jGrOinLPuOrsp7zJ9sv0z0gme8NeGDYQlv4dykrAE/bLTIwxpkHZleMNKDM9mX0Fxzjcph+UHYN9X4Y7JGOMaXCWOBpQf7eDfL30dArsQkBjTDNkiaMB9XMTx4r8thDT2vo5jDHNkiWOBpQcH0O3tq1Ys/MIdBpgicMY0yxZ4mhgmenJrN3pjs2x63MoLwt3SMYY06AscTSw/hnJbN53hKIOA6DkCOz/OtwhGWNMg7LE0cC8V5B/He12kNsV5MaYZsYSRwPrn5ECwIojHSE63vo5jDHNjiWOBpaWHEfb1rGs2XUU0vpb4jDGNDuWOBqYiNA/I5k1Ow8fH5ujvMncUssYY+rNEkcIZKYn8+WuAko7DYRjeXBwc7hDMsaYBmOJIwQyM5IpLitnW2xvp8Caq4wxzYgljhDw3nokpygdomIscRhjmhVLHCHQo30i8TFRfL67CDr2s8RhjGlWLHGEgCdK6NspmbW+HeSq4Q7LGGMahCWOEOmfkczaHXlo+iAoPACHt4U7JGOMaRCWOEIkMyOZvKJS9iT2dQqsucoY00xY4ggR7xXkq0q6gHgscRhjmg1LHCHSJy2JKIEv9hRDhz6WOIwxzYYljhBJiPXQs0Mia3f4dJAbY0wzEFDiEJGbRSRZHM+KyEoROT/UwUW6zIxk1uzIg/RBULAb8naGOyRjjKm3QI84rlHVPOB8oA3wA+DBkEXVTPTPSGbn4SLy2mQ6BXbUYYxpBgJNHOI+fxt4UVXX+JSZamSmOx3ka8q6AWKJwxjTLASaOFaIyAc4ieN9EUkC7JavtfDeeuyTDeAAACAASURBVOTzfWXQrpclDmNMsxAd4HLXAoOATap6VETaAj8MXVjNQ5vWsWSkxDv9HBmD4Jsl4Q7JGGPqLdAjjm8BG1T1kIh8H7gDOFzbSiIyXkQ2iMhGEZnup36U29FeKiITfMrHikiOz6NIRC5z63qIyP/cbc4VkdgAX0NYZLpXkJM+EPK2Q8HecIdkjDH1Emji+BtwVEQGAr8EvgZeqGkFEfEAM4ELgExgkohkVlpsKzAVmO1bqKoLVHWQqg4CzgaOAh+41X8EZqhqL+AgztFQk5WZkcLXews41n6AU7DLmquMMZEt0MRRqqoKXAo8rqozgaRa1hkObFTVTapaDMxx16+gqltUdTU195dMAN51m8gEJ5G86tY9D1wW4GsIi8z0ZMoVvozq4RRYP4cxJsIF2seRLyK/xjkNd6SIRAExtazTGfC9s18ucHrwIXIV8Bd3uh1wSFVLfbbZ2d9KIjINmAaQlpZGdnZ2HXYNBQUFdV4XIP+okxNfXfIlveI7kb/6Q9aWDanz9mpT33gbk8UaOpEUbyTFCpEVb6hiDTRxTAS+h3M9xy4R6QY81ODRVCIi6cAA4P1g11XVp4GnAYYOHapjxoypUwzZ2dnUdV03Du5b+gGlSZ1IOPkMEnZ8Rsd6bK829Y23MVmsoRNJ8UZSrBBZ8YYq1oCaqlR1F/ASkCIiFwFFqlpjHwewHejqM9/FLQvGlcAbqlrizu8HUkXEm/Dqss1GJSI+V5APhEPfQOHBcIdljDF1FugtR64ElgJX4HyZ/8/3LKhqLAN6u2dBxeI0Ob0VZHyTgJe9M24/ywKcfg+AKcC/gtxmo8tMT2H9rjzKOg10CnauDm9AxhhTD4F2jv8WGKaqU1R1Mk7H9+9qWsHth7gJp5lpHfCKqq4RkXtF5BIAERkmIrk4CekpEVnjXV9EuuMcsSystOnbgV+IyEacPo9nA3wNYdM/I5miknK+ie3pFFgHuTEmggXaxxGlqnt85vcTQNJR1XnAvEpld/pML8NpbvK37hb8dHyr6iacxBUxMr1XkB+M4eTkLpY4jDERLdDE8Z6IvM/xZqOJVEoIpnq9OiYS64li7Y48Ls0YBDtzwh2SMcbUWaCd47finKGU5T6eVtXbQxlYcxLjieKUToms3el2kO/fCEV54Q7LGGPqJNAjDlT1NeC1EMbSrPVPT2H+ut3oWVnObYV3fwEnnRnusIwxJmg1HnGISL6I5Pl55IuI/WQOQmZGMgeOFLM3sZ9TsH1leAMyxpg6qjFxqGqSqib7eSSpanJjBdkcVNxiPS8e0gbA0qegpDDMURljTPBszPFG0jc9GRGcO+WO/wMc2gpLHgt3WMYYEzRLHI0kMS6a7u1aO1eQ9xgFmZfB4r/AoW21r2yMMU2IJY5GlJme7JxZBXD+fc7z/BqvozTGmCbHEkcjysxIZuuBo+QVlUBqNzjrFljzBmxeHO7QjDEmYJY4GpH3CvJ1O9yjjhE/g5Ru8O7tUFZaw5rGGNN0WOJoRN4zq9Z4E0dMAoz7PexZA8v/EcbIjDEmcJY4GlHHpHjaJ8Yd7+cA6Hcx9BgNC+6HI/vDF5wxxgTIEkcj6+8dm8NLBC74IxwrgP/cF77AjDEmQJY4GllmRjJf7c7nWGnZ8cKO/WD4NFjxnN051xjT5FniaGT9M5IpLVe+2l1wYsWY6dCqHcy7DVTDE5wxxgTAEkcj65+RArhXkPtKSIVz74Jtn8Lnr4YhMmOMCYwljkZ2UttWtGkVw9urd1StHPR9yBjsXBR4rKBqvTHGNAGWOBpZVJTwk7G9WPzVPhZs2FO5Ei74E+TvhMUPhydAY4yphSWOMJj8re50b9eK3/97HaVl5SdWdh0OAyfBf2fC/q/DE6AxxtTAEkcYxEZH8etv92PjngJeXubnJofn3g2eWHj/N40dmjHG1MoSR5icn5nG6T3aMmP+lxwuLDmxMqkTjL4NvnwPvvwgPAEaY0w1LHGEiYjwu4syOXi0mCcWbKy6wOk3Qrte8N50KC1u/ACNMaYaljjC6NTOKXz3tC7885MtbN1/9MTK6FgY/yAc+Br+97fwBGiMMX5Y4gizW8f1wRMlPPjeuqqVvc+DU8bDwj9B/q7GD84YY/ywxBFmacnx3DC6J/M+38WyLQeqLjDuD1BWDB/e3eixGWOMPyFNHCIyXkQ2iMhGEZnup36UiKwUkVIRmVCprpuIfCAi60RkrYh0d8vPcdfJEZGPRaRXKF9DY7h+VA86Jcdz3ztrKS+vdLuRdj3hWzfBqpdh6//CE6AxxvgIWeIQEQ8wE7gAyAQmiUhmpcW2AlOB2X428QLwkKr2A4YD3qvl/gZcraqD3PXuaPjoG1er2GhuG9+H1bmH+deq7VUXGPlLSEqHd2+D8rKq9cYY04hCecQxHNioqptUtRiYA1zqu4CqblHV1cAJV8G5CSZaVee7yxWoqrf3WIFkdzoF8HPvjshz2aDODOicwp/e20BhcaXkEJcI590HO3Pgs1nhCdAYY1yiIboTq9v0NF5Vr3PnfwCcrqo3+Vn2OeAdVX3Vnb8MuA4oBnoAHwLTVbVMREYCbwKFQB5whqrm+dnmNGAaQFpa2pA5c+bU6XUUFBSQmJhYp3WDteFAGQ8sLeLyXjFc2iv2xEpVBn/2axIKt7N0+N8ojfEfU2PGW18Wa+hEUryRFCtEVrz1jXXs2LErVHVolQpVDckDmAA84zP/A+DxapZ9DphQad3DwMlANPAacK1b9zpOAgK41Xcf1T2GDBmidbVgwYI6r1sXN7y4XPve8a7uOlxYtXJHjupdKarzbq92/caOtz4s1tCJpHgjKVbVyIq3vrECy9XPd2oom6q2A1195ru4ZYHIBXLUaeYqxTnCOE1EOgADVdXbSzwXOLOhAm4Kpl/Ql7Jy5eH3N1StTB8IQ6bC0qdhj5/Td40xphGEMnEsA3qLSA8RiQWuAt4KYt1UN1EAnA2sBQ4CKSJyilt+HtCsvkFPateaqSO68+rKXL7YfrjqAmf/zunzePd2G/DJGBMWIUsc7pHCTcD7OF/ur6jqGhG5V0QuARCRYSKSC1wBPCUia9x1y4BfAR+JyOeAAH93t3k98JqIrMJp/ro1VK8hXH4ythepCTH8/t/rvE13x7VuB2PvgM0LYd3b4QnQGNOiRYdy46o6D5hXqexOn+llOE1Y/tadD2T5KX8DeKNhI21aUhJiuOW8U7jzX2uYv3Y35/fvdOICQ69xxid//7fQ61yIbRWWOI0xLZNdOd5EfW94N3p1TOSBd9dTXFppzA5PNFzwRzi8FZY8Gp4AjTEtliWOJiraE8Vvv92PzfuO8OKn31RdoMdI6H85fDwDDm1t/ACNMS2WJY4mbEyfDozs3Z5HP/qKQ0f93Fr9vPsAgQ8i/uJ5Y0wEscTRhIkIv72wH/lFJfz1o6+qLpDaFUb+Atb+CzYtbPwAjTEtkiWOJq5vp2QmDuvGi//9hq/3FlRd4MyfQmo35/TcstLGD9AY0+JY4ogAvzjvFOJjPDwwb33VypgE59bre9fB8mcbPzhjTItjiSMCdEiK48dje/Lhut0s2biv6gJ9L4KTx8CC3xNfuLuxwzPGtDCWOCLENSN60Dk1gfv+vY6yymN2iMAFfwKFISt+AV9+EJ4gjTEtgiWOCBEf42H6BX1ZtzOP11bkVl2gQx+YtoBjcR1g9hXw0X02docxJiQscUSQi7LSOa1bKg99sIGCY346wtv1ZOVpf4RB34fFD8OLl0PB3sYP1BjTrFniiCAiwh0XZbI3/xhPLfza7zLlnji4bCZc8jhs+x88NcqGnDXGNChLHBHmtG5tuGRgBk8v2sT2Q4U1LPgDuHY+RMfCc9+G/z5hd9M1xjQISxwR6PYL+gLw0Ht+Ts/1lZ4F0xZC73Hw/q/h/6ZCUZXBEo0xJiiWOCJQ59QErhvZgzdzdpCz7VDNCyekwlUvwbn3OLdh//tY2L22cQI1xjRLljgi1I1jetE+MY7731lbdcyOykTgrJ/DlLfgWD48cw6smts4gRpjmh1LHBEqMS6aX51/Csu/Oci8z3cFtlL3s+BHiyBjMLwxDd7+OZQUhTZQY0yzY4kjgl0xtCt9OyXxwLvrKCoJ8JqNpE4w+S0YcTOs+Cf8Yxwc9HPbdmOMqYYljgjmiRLuuDCT3IOFPLdkSxArRsN598JVs+HAZueUXbva3BgTIEscEe6s3u05p29HZv5nI/sKjgW3ct8L4UfZkNLVrjY3xgTMEkcz8JsL+1FYUsaM+V8Gv3Lbk+G6+TDYrjY3xgTGEkcz0LNDIt8/4yReXrqVVXvrMCZHTAJcalebG2MCY4mjmfj5ub3p0ymZR1YcY+aCjbWfoutPxdXmcXa1uTGmWpY4monUVrG8fuOZnJ7u4aH3N3DjrJX+b4RYm/QsmJYNp4x3rzafYlebG2NOYImjGUmI9fCjrDjuuLAf89ft5rKZn/gfbrbWDaXCxFnOmVfr3oG/jYCPZ0C+DRJljAlx4hCR8SKyQUQ2ish0P/WjRGSliJSKyIRKdd1E5AMRWScia0Wku1suIvJ7EfnSrftZKF9DpBERrht5Mi9eM5wDR4q57PFP+HBtHb7wRZxrPaa+Aymd4cO74S/94OVJsH6ejW9uTAsWssQhIh5gJnABkAlMEpHMSottBaYCs/1s4gXgIVXtBwwH9rjlU4GuQF+3bk6DB98MnNmrPW/dNIKT2rfiuheW88iHX1JeeeTAQJx0JlzzHty0HM68CXKXw5xJMCMT5t8F+/3f3t0Y03yF8ohjOLBRVTepajHOF/ylvguo6hZVXQ2U+5a7CSZaVee7yxWo6lG3+kbgXlUtd+v2YPzq0qYVr95wJt85rTOPfPgV015cTl5RSd021r6303T1i7XOhYMZp8GSx+Cx0+AfF0DObCg+0rAvwBjTJIUycXQGtvnM57plgTgFOCQir4vIZyLykHsEA9ATmCgiy0XkXRHp3YAxNzvxMR7+fMVA7r44k+wNe7ns8U/YuCe/7hv0xDgXDn5vjpNEzrkLCnbDmzfCw33g7Zshd4WdjWVMMyZ1Om0zkA07fRbjVfU6d/4HwOmqepOfZZ8D3lHVV33WfRYYjNOcNReYp6rPikgBcJeq/llEvgPcoqoj/WxzGjANIC0tbcicOXVr0SooKCAxMbFO64ZDTfFuOFDGzJwiisvg+qw4hqRFN8xOVUk5vJb0nfPpsPcTPOXFFLQ+iV2dzmV32hhKYpODjrWpiaRYIbLijaRYIbLirW+sY8eOXaGqQ6tUqGpIHsC3gPd95n8N/LqaZZ8DJvjMnwEs9Jn/ATDTnV4P9HCnBThcWyxDhgzRulqwYEGd1w2H2uLdceioXvL4x3rS7e/oQ++t19Ky8oYNoPCQ6rJnVZ8eq3pXsuo97VTnTlb9ar5qWWlQsTYlkRSramTFG0mxqkZWvPWNFViufr5TQ9lUtQzoLSI9RCQWuAp4K4h1U0Wkgzt/NuAdfehNYKw7PRqow302Wq70lATmTjuDiUO78viCjVz7/DIOH61jv4c/8Skw9Bq4/j9w4xIYfj1sXgSzvguPZMGCP9jdeI2JcCFLHKpaCtwEvA+sA15R1TUicq+IXAIgIsNEJBe4AnhKRNa465YBvwI+EpHPcY4s/u5u+kHgu275A8B1oXoNzVV8jIcHvzuA319+Kp9s3MclMz9mw6569HtUJ60/jH8AfrkerngOOvSBhX+Cvw6EFy4lfcd7sHMVlDVg4jLGhFwDNXL7p6rzgHmVyu70mV4GdKlm3flAlp/yQ8CFDRtpyyMiXH36SfTtlMQNs1Zy+ROf8NCEgVyYld7wO4uOg/6XO49D25wzsHJm0edQNnz5N/DEQacBzgBTnU9zntufAlGeWjdtjGl8IU0cpukbclJb3vnpWdw4awU/mb2S1dtP5rZxffFESWh2mNoVxtwOo2/j0/fmcEbXWNi+EnZ8BqtehmXugWVMa0gfeDyRZAx27uQrIYrLGBMwSxyGtOR45kz7Fve8vYanFm5i7Y48Hr1qMG1ax4ZupyIUJaTDqWPg1O86ZeVlsO8rJ4nscJPJ0r9DmTvOSHyKm0ROO350ktzZkokxjcwShwEgNjqK318+gKwuKfzuzTVc/PjHPPWDIfTPSGm8IKI80LGv8xg0ySkrK4E9644nku0rYcmjUO7e8qR1hxMTScZgSOzYeDEb0wJZ4jAnmDisG306JXPDiyv47t+W8MfvZnHpoECv2wwBT4xzx970LBgy1SkrKYLdXxxPJDs+g68+ANxrkuKSITnDORpJ6QzJXdznzpDSxamLbR2uV2RMxLPEYaoY1DWVt396Fj95aSU3z8lh+ZaD3DimJxmpCeEOzRETD12GOg+vYwWwa7WTRA5+A3nb4XCuU3bEz4iG8aluEulcNakku/Mx8Y33moyJIJY4jF8dkuJ46frT+f2/1/Hcki289L9vGNOnI5OGd2Nsnw5Ee5rYHfnjEp0bMp50ZtW60mNOIsnbAYe3Q16u+7zdec5dCoUHq67Xqn3FEUvvfIXyT5x+lvhk99n3keoc6XjsX8o0f/YpN9WK8URx9yX9uWZED+Yu38ory3P5zwvLSUuO48qhXblyaFe6tm0V7jBrFx3nnJHV9uTqlyk+6iSWE5JKrvN8cDMdD2yFHe9S0RxWndhEP0ml0iMu+cTpmHiIjneG8PV9tk5/00RZ4jC16tauFbeO68vPzz2F/6zfw8tLt/L4go08vmAjo3p3YNLwbpzTryMxTe0oJBixraB9L+fhxyfZ2YwZNQqK86HosM8jr9K893HIec7b4XTuFx2GY3mg5X6371d0NQmlynM8RCec8NxlWy78bwNERTv9RFExzrPvdF3qojwgUZbUWjhLHCZgMZ4oxvXvxLj+ncg9eJRXlufyyrJt3DBrBR2S4rhiSBeuGtaNbu0i4CikLqKijh8p1EV5ORQXnJhgjuVDaaHT4e/vufQYlBRCaZHPc5GTmPJ3+V8H6AUQyqFSJArE45NIPM77U6XMna5S5l0+itPyj8DGVLc+6nhiEjmxDKl9mROWE3fafcb7VLnM33K+ZSeu03N7LhS9X2lZKk1XWtd3m7UtV7k+6LLjE92+2QxHs6BVWxqSJQ5TJ13atOIX553Cz87uRfaGvcxZtpUnF37NE9lfM7J3e64a1o3zMtOIjY7go5CGFhXl9o8k44xFFgKqUHqMxQs/YuS3zoDyEueUZu9zxXRpgHWlUFZ8vK68HLTMueZGy5wjqHLf50rT3uVPKHPn3bLSQnWO+FTdcnWWQY8vV/HQSs/lNSynbp23ebEOZd73FHVnlfTSUtjjqbQsVZevmA5mOZ/6BnAywJGbLXGYpiXaE8W5mWmcm5nGzsOFvLIsl1eWb+Mns1fSrnUsE4Y6RyE92tvpr41CBGLiKYtuDa3bhTuagKzOzmbMmDHhDiNgH4cjXq0hwdRQtnDRQka389/8Wh+WOEyDSU9J4OZze3PT2b1Y9NVeXv7fVp5ZvJmnFm7iWye3Y9Lp3RjXP424aLsHlTFBET/NYgHQqBjnSLeBWeIwDc4TJYzt05GxfTqyO6+IV1fk8vLSrfzs5c9o0yqG757WhauGdwt3mMaYOrLEYUIqLTmen4ztxY2je/Lxxn3MWbaV55Zs4ZmPN9M1KYqzDnzOwC4pDOyaSu+OiU3v+hBjTBWWOEyjiIoSRp3SgVGndGBv/jFeW5nL20u/5N+rd/Dy0q0AJMR4OLVzMgO7pJLVNZVBXVLp2jYBsVM/jWlSLHGYRtchKY4bRvekr25j1KjRbNl/hNW5h8nZdojVuYd44dNvKP54MwBtWsWQ1SW14qgkq0sqHZLiwvwKjGnZLHGYsIqKEk7ukMjJHRK5bLBzM8WSsnI27MpnVe4hVm87zKrcQzy+YC/l7gkjnVMTGNg1xU0oqQzokkJinH2UjWks9t9mmpwYTxSndk7h1M4pXH26U3a0uJQvtuexatshVuU6j3mf7wKcE016dUh0EknXFHq0b016SgIZqfG0irWPuDENzf6rTERoFRvN8B5tGd7j+IVMB44Un3BUkr1hD6+tzD1hvZSEGNJT4slITah47pQcT3pqPBkpCXRKiSc+xk4PNiYYljhMxGrbOrbitF8AVWXH4SK2HTjKzsOF7DhUxM7Dhew8VMSOw0V8tvUgB4+WVNlOu9axpKfGk57iJBfv0Yp3vlOK3V7dGF+WOEyzISJ0Tk2gcw3jhhQWlznJ5HAROw45z975rfuP8umm/eQXlVbaLiTHCh1XLiQ5IYak+GiS42NITvA+x/iZj64ot9uumObGEodpURJiPRWd8dUpOFbKzkOF7DhcxE43uXy2YTOtUxPJKyphf0ExW/YdIa+olLzCEkrLa763UHxM1AkJJclnOjE+mvhoD/ExHuJjoo4/u2VxbllctLfOQ7zPtCfKTlU2jc8ShzGVJMZF0zstid5pSRVl2TE7GDNmSJVlVZXCkjLyCkvJKyohr7DEfXbm893k4lt26GgxWw8cJa+whPxjpRSXBnGr9UpiPEJ8tIe4Somn6EghT2z4LzEewRMVRUyUEO0Roj3e6ShiPEJ0VBTRHiHGE0V0lL/6E5f1RAlRUYJHBE8URIkQJXJCeZRb7ok6XucRQcS5q4BveZTA3qPlbD9USJSA4JQhx7ctONNOmTMtPs/edUSOP5vQssRhTD2ICK1io2kVG13nvpDycuVYaTlFJWUUlZZRVOJOl5QdLy8p51hpWcV0xbNP2TGf9XcXFSBAUUk5pWWllJQppeXllJYppeVKaVk5Je5zaZlS4lMXFov+06Cbc/MM4iYeb4KhotyZr7wcvvN+tgFCSUkxsZ98iLt4xf4q9u2WnljmXa5qUvN3G6pAtyFVJk5c7uiRo8wZcLTBhzqwxGFMmEVFCQmxHhJiG+7sruzsbMaM+VbQ66l6E4tPMvFJMmXlSrkqZeVUTDvzx8vLVSkvV8p8ysvLoaxSuaqzjbXr1tGnT193W6A4z7jz5eos63321h8v89b71h1fVt07onvnqZivWnf8JrRapdw7v3PHDtIz0vDeidb35rQV6/vcGv14GVWXp1LlCcupn7LAlvNO7NlbGJI+tpAmDhEZD/wV8ADPqOqDlepHAY8AWcBVqvqqT1034BmcgQsU+LaqbvGpfxS4RlWrb6w2xgRFRIjxCDEeSKBxTlNul7+RMcNCND5JCGRn72fMmAHhDiMg2dnZITkrMGSne4iIB5gJXABkApNEJLPSYluBqcBsP5t4AXhIVfsBw4E9PtseCrQJQdjGGGNqEcrzBIcDG1V1k6oWA3OAS30XUNUtqroaOKF30E0w0ao6312uQFWPunUe4CHgthDGbowxphri2z7WoBsWmQCMV9Xr3PkfAKer6k1+ln0OeMfbVCUilwHXAcVAD+BDYLqqlonIzUCUqs4QkYLqmqpEZBowDSAtLW3InDlz6vQ6CgoKSEyMnNawSIrXYg2dSIo3kmKFyIq3vrGOHTt2haoOrVzeVDvHo4GRwGCc5qy5wFQReRe4AhhT2wZU9WngaYChQ4dqXYd6zI6wYS0jKV6LNXQiKd5IihUiK95QxRrKxLEdp2Pbq4tbFohcIEdVNwGIyJvAGcAuoBew0T0lrZWIbFTVhh9U1xhjjF+hTBzLgN4i0gMnYVwFfC+IdVNFpIOq7gXOBpar6r+BTt6F3KYqSxrGGNOIQtY5rqqlwE3A+8A64BVVXSMi94rIJQAiMkxEcnGan54SkTXuumXAr4CPRORznGta/h6qWI0xxgQupH0cqjoPmFep7E6f6WU4TVj+1p2Pc31HTduPjB4qY4xpRkJ2VlVTIiJ7gW/quHp7YF8DhhNqkRSvxRo6kRRvJMUKkRVvfWM9SVU7VC5sEYmjPkRkub/T0ZqqSIrXYg2dSIo3kmKFyIo3VLHaQAHGGGOCYonDGGNMUCxx1O7pcAcQpEiK12INnUiKN5JihciKNySxWh+HMcaYoNgRhzHGmKBY4jDGGBMUSxw1EJHxIrJBRDaKyPRwx1MdEekqIgtEZK2IrHHvINykiYhHRD4TkXfCHUttRCRVRF4VkfUisk5Egh9ar5GIyC3uZ+ALEXlZRBp+FJ96EJF/iMgeEfnCp6ytiMwXka/c5yYz1k418T7kfhZWi8gbIpIazhi9/MXqU/dLEVERad8Q+7LEUY0AB6JqKkqBX6pqJs7NIH/ShGP1uhnnVjSR4K/Ae6raFxhIE41bRDoDPwOGquqpOCNvXhXeqKp4DhhfqWw68JGq9gY+cuebiueoGu984FRVzQK+BH7d2EFV4zmqxoqIdAXOx7nTeIOwxFG9WgeiaipUdaeqrnSn83G+2DqHN6rqiUgX4EKcoYGbNBFJAUYBzwKoarGqHgpvVDWKBhJEJBpoBewIczwnUNVFwIFKxZcCz7vTzwOXNWpQNfAXr6p+4N6LD+BTqrltUmOr5r0FmIEz8F2DnQlliaN6nYFtPvO5NOEvYy8R6Y4zjsn/whtJjR7B+SCX17ZgE9AD2Av8021ae0ZEWoc7KH9UdTvwMM4vy53AYVX9ILxRBSRNVXe607uAtHAGE6RrgHfDHUR1RORSYLuqrmrI7VriaEZEJBF4Dfi5quaFOx5/ROQiYI+qrgh3LAGKBk4D/qaqg4EjNK2mlApu38ClOMkuA2gtIt8Pb1TBUef6gIi4RkBEfovTTPxSuGPxR0RaAb8B7qxt2WBZ4qhefQaianQiEoOTNF5S1dfDHU8NRgCXiMgWnOa/s0VkVnhDqlEukKuq3iO4V3ESSVN0LrBZVfeqagnwOnBmmGMKxG4RSQdwn/eEOZ5aichU4CLgam26F8P1xPkRscr9f+sCrBSRTjWuFQBLHNWrGIhKRGJxOhnfCnNMfokzHOKzwDpV/Uu446mJqv5aVbuoanec9/Q/qtpkfxWr6i5gm4j0cYvOAdaGMaSabAXOEJFW7mfiHJpoR34lP9q/zwAAA41JREFUbwFT3OkpwL/CGEutRGQ8TlPrJap6NNzxVEdVP1fVjqra3f1/ywVOcz/T9WKJoxrVDUQV3qiqNQL4Ac6v9xz38e1wB9WM/BR4SURWA4OAP4Q5Hr/co6JXgZXA5zj/303q9hgi8jLwX6CPiOSKyLXAg8B5IvIVzlHTg+GM0Vc18T4OJAHz3f+1J8MapKuaWEOzr6Z7lGWMMaYpsiMOY4wxQbHEYYwxJiiWOIwxxgTFEocxxpigWOIwxhgTFEscxjQgERkTzjv+ishUEXn8/9u7nxCbwjCO49/fNKUJxYINImw0xYjuBqVkK0LKn4W1jZ2NUrKRZKVYkllIsbGQP2XKFGPINEVRg7JSksxixph5LM5zxzFmxj1DZur+Pqtz3/Pe9zzv4p6399zO88zW9a05eOEws3GZFdpsWl44rOlIOiypJ1/euly/WUoalHQh61k8kLQk2zskPS7VX1ic7Wsl3ZfUJ+m5pDV5iQWl+h2d+Rb3xBgeSjqbcbyWtC3bf9kxSLotaXspvnMZ331JtRxnQNKu0vArsv2NpFMNzvu8pD5gztYasbnDC4c1FUnrgAPAlojoAEaBQ3l6PtAbEe1AF1C/6V4FTmT9hf5SeydwMSI2UOSEqmd43Qgcp6jjsprizf7JtEZELfuemqJP2XyKFC3twFfgDLAT2AOcLvWrAXuB9cB+SZsbmPeTiNgQEY8aiMOaXOtsB2D2n+0ANgFPcyPQxs+kemPA9Ty+BtzMehyLIqIr268ANyQtBJZFxC2AiBgCyDF7IuJDfn4BrAImuyHXk1E+yz5/8g24k8f9wHBEjEjqn/D9exHxKa9/E9hKkcV1qnmPUiTINGuIFw5rNgKuREQjVdtmmo9nuHQ8ytS/s+FJ+nzn1ycB5dKvI6VMrGP170fEWBZuqpsYdzD9vIciYnSKGM1+40dV1mweAPskLYXxetcr81wLsC+PDwKPIuIL8Ln+HwRFMsmurLT4QdLuHGde1j/4W++ADkktWfKzNoMxdua82iiq6XUz/bzNKvGOw5pKRLyUdBK4K6kFGAGOAe8pijTV8vxHiv8EoEj1fSkXhgHgaLYfAS5LOp3j7P8HIXYDbylSt7+iyHRbVQ/Fo6flwLWI6AWYZt5mlTg7rlmSNBgRC2Y7DrO5zo+qzMysEu84zMysEu84zMysEi8cZmZWiRcOMzOrxAuHmZlV4oXDzMwq+QHpCzHU1De7MgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUN8puFoEZtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6280b3-ace4-44c9-e7c0-30ac7b8cab8d"
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
        "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9530133333333334\n",
            "0.95064\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}