{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bootstrap_assignment1_(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sNKZq4XrXQh"
      },
      "source": [
        "# <font color='red'><b>Bootstrap assignment</b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAHap1Z3FZC-"
      },
      "source": [
        "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
        "\n",
        "Every Grader function has to return True.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuxBq_bvrwh2"
      },
      "source": [
        "<font color='blue'> <b>Importing packages</b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6ag91ijrQOs"
      },
      "source": [
        "import numpy as np # importing numpy for numerical computation\n",
        "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
        "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric\n",
        "import random"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcHOsONTt1K_"
      },
      "source": [
        "boston = load_boston()\n",
        "x=boston.data #independent variables\n",
        "y=boston.target #target variable"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc1htEFYuLRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549ac443-82f2-4bb1-b4c4-5e091af7ca71"
      },
      "source": [
        "x"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "        4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "        9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "        4.0300e+00],\n",
              "       ...,\n",
              "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        5.6400e+00],\n",
              "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "        6.4800e+00],\n",
              "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        7.8800e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEa_HqRZloH4"
      },
      "source": [
        "## <font color='red'><b>Task 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ5q8IxHNRk3"
      },
      "source": [
        "<font color='red'> <b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJCFCaOzl7Mr"
      },
      "source": [
        "*  <font color='blue'><b>Creating samples</b></font><br>\n",
        "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
        "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
        "    \n",
        "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
        "* <font color='blue'><b> Create 30 samples </b></font>\n",
        "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
        "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
        "Make sure each sample will have atleast 3 feautres/columns/attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUqFEBSvNjCa"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqi9AhCYNq3Z"
      },
      "source": [
        "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lLBnZHXOFln"
      },
      "source": [
        "*  Build a regression trees on each of 30 samples.\n",
        "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
        "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kls23JLnSN23"
      },
      "source": [
        "<font color='red'> <b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz2GchkGSWnh"
      },
      "source": [
        "*  <font color='blue'><b>Calculating the OOB score </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGHkVV2kSibm"
      },
      "source": [
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
        "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK860ocxTyoz"
      },
      "source": [
        "# <font color='red'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dme-N6TUCrY"
      },
      "source": [
        "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
        "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
        "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
        "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
        "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
        "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6UcH1x9Uwrj"
      },
      "source": [
        "# <font color='red'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOC_AgsLU7OH"
      },
      "source": [
        "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYs5jSFdVILe"
      },
      "source": [
        "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
        "Predict the house price for this point as mentioned in the step 2 of Task 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6gxZEsFWm-8"
      },
      "source": [
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2fHTdS_zpgG"
      },
      "source": [
        "# <font color='blue'> <b>Task - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0yGBuryOwHz"
      },
      "source": [
        "<font color='blue'><b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJXX8vf3z073"
      },
      "source": [
        "*  <font color='blue'> <b>Creating samples</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSVaWG1F4uCZ"
      },
      "source": [
        "<font color='Orange'><b>Algorithm</b></font>\n",
        "\n",
        "![alt text](https://i.imgur.com/BTVYXQ1.jpg/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxNjXsMhmuCP"
      },
      "source": [
        "def generating_samples(input_data, target_data):\n",
        "      selecting_rows_l = random.sample(range(0,506),303)    \n",
        "      selecting_rows = np.array(selecting_rows_l)    \n",
        "      replicating_rows_l = random.sample(selecting_rows_l,203)    \n",
        "      replicating_rows = np.array(replicating_rows_l)    \n",
        "      num_selecting_columns = random.randint(3,13)    \n",
        "      selecting_columns = np.array(random.sample(range(0,13),num_selecting_columns))    \n",
        "      sample_data = input_data[selecting_rows[:,None],selecting_columns]    \n",
        "      target_of_sample_data = target_data[selecting_rows_l]    \n",
        "      \n",
        "      replicated_sample_data = input_data[replicating_rows[:,None], selecting_columns]\n",
        "      target_of_replicated_data = target_data[replicating_rows]    \n",
        "      \n",
        "      final_sample_data = np.vstack((sample_data, replicated_sample_data))    \n",
        "      final_target_data = np.vstack((target_of_sample_data.reshape(-1,1),target_of_replicated_data.reshape(-1,1)))\n",
        "      return final_sample_data, final_target_data, selecting_rows, selecting_columns"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_oWoN97BhDY"
      },
      "source": [
        "*  <font color='blue'><b> Write code for generating samples</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MivEQFlm7iOg"
      },
      "source": [
        "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVvuhNzm7uld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a17667-5c20-42e2-aa59-a347caf0f6a2"
      },
      "source": [
        "def grader_samples(a,b,c,d):\n",
        "    length = (len(a)==506  and len(b)==506)\n",
        "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
        "    rows_length = (len(c)==303)\n",
        "    column_length= (len(d)>=3)\n",
        "    assert(length and sampled and rows_length and column_length)\n",
        "    return True\n",
        "a,b,c,d = generating_samples(x, y)\n",
        "grader_samples(a,b,c,d)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4LSsmn4Jn2_"
      },
      "source": [
        "*  <font color='blue'> <b>Create 30 samples </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec7MN6sL2BZ"
      },
      "source": [
        "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXlKWjCcBvTk"
      },
      "source": [
        "# Use generating_samples function to create 30 samples \n",
        "# store these created samples in a list\n",
        "list_input_data =[]\n",
        "list_output_data =[]\n",
        "list_selected_row= []\n",
        "list_selected_columns=[]\n",
        "\n",
        "for i in range(0,30):\n",
        "  a,b,c,d, = generating_samples(x, y)\n",
        "  list_input_data.append(a)\n",
        "  list_output_data.append(b)\n",
        "  list_selected_row.append(c)\n",
        "  list_selected_columns.append(d)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXUz9VFiMQkh"
      },
      "source": [
        "<font color='cyan'> <b>Grader function - 2 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCvIq8NuMWOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a3b8513-9a6a-4284-b876-83a8263b8939"
      },
      "source": [
        "def grader_30(a):\n",
        "    assert(len(a)==30 and len(a[0])==506)\n",
        "    return True\n",
        "grader_30(list_input_data)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pv-mkZkO6dh"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whaHCPB0O8qF"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBy4zXSWPtU8"
      },
      "source": [
        "<font color='orange'><b>Flowchart for building tree</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xvH06HPQBdP"
      },
      "source": [
        "![alt text](https://i.imgur.com/pcXfSmp.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRwPO_uHQjul"
      },
      "source": [
        "*  <font color='blue'><b> Write code for building regression trees</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWQp6tRwMthq"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "list_of_all_models = []\n",
        "\n",
        "for input_data, taget_data in zip(list_input_data, list_output_data):\n",
        "  regressor = DecisionTreeRegressor(max_depth=None) \n",
        "  regressor.fit(input_data,taget_data)\n",
        "  list_of_all_models.append(regressor)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHHt9JaSAR-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec13669c-10cb-435d-8052-34231acc70e2"
      },
      "source": [
        "regressor1 = DecisionTreeRegressor(max_depth=None) \n",
        "regressor1.fit(list_input_data[1],list_output_data[1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21j8BKfAQ1U8"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q0mTBD2RBx_"
      },
      "source": [
        "![alt text](https://i.imgur.com/sPEE618.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e-UamlHRjPy"
      },
      "source": [
        "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnIMT7_oR312"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzeP1Y2L25UR"
      },
      "source": [
        "array_of_y = []\n",
        "for i in range(0,30):\n",
        "  data_point = x[:, list_selected_columns[i]]\n",
        "  y = list_of_all_models[i].predict(data_point)\n",
        "  array_of_y.append(y)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjWtCBAGOJSO",
        "outputId": "b9f084a9-af9d-4929-c798-db165308a9f2"
      },
      "source": [
        "predict_y_of_datapoint = np.array(array_of_y)\n",
        "predict_y_of_datapoint=predict_y_of_datapoint.transpose()\n",
        "mean_predict_y_of_datapoint = np.mean(predict_y_of_datapoint, axis=1)\n",
        "mean_predict_y_of_datapoint.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go0zId5KOV5M",
        "outputId": "bcb69ab2-6052-47f0-f250-c07aed65c309"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from statistics import median\n",
        "print(mean_squared_error(y, mean_predict_y_of_datapoint))\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.580992497573695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuclPDMnSz8F"
      },
      "source": [
        "<font color='blue'><b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESb9FSIDTM5V"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB-d6NMETbd9"
      },
      "source": [
        "![alt text](https://i.imgur.com/95S5Mtm.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW3GOcFzTqbt"
      },
      "source": [
        "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqcS03pUYSZ"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fog_6DNdS-h_"
      },
      "source": [
        "predicted_y = []\n",
        "for i, point in enumerate(x):\n",
        "  model_y_pred = []\n",
        "  for j, model in enumerate(list_of_all_models):\n",
        "    if i not in list_selected_row[j]:\n",
        "      model_y_pred.append(model.predict(point[list_selected_columns[j]].reshape(1,-1)))\n",
        "  predicted_y.append(np.median(np.asarray(model_y_pred)))\n",
        "OOB_Score = mean_squared_error(y,np.asarray(predicted_y))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw7W9YW4RpFe",
        "outputId": "97a967b0-53a5-4ab1-e5a2-c87da223a99a"
      },
      "source": [
        "print(\"OOB Score is: \",OOB_Score)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OOB Score is:  16.434470855902013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbuiwX3OUjUI"
      },
      "source": [
        "# <font color='blue'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceW5-D88Uswi"
      },
      "source": [
        "def task2(x,y):\n",
        "  list_input_data =[]\n",
        "  list_output_data =[]\n",
        "  list_selected_row= []\n",
        "  list_selected_columns=[]\n",
        "\n",
        "  for i in range(0,30):\n",
        "    a,b,c,d, = generating_samples(x, y)\n",
        "    list_input_data.append(a)\n",
        "    list_output_data.append(b)\n",
        "    list_selected_row.append(c)\n",
        "    list_selected_columns.append(d)\n",
        "  \n",
        "  list_of_all_models = []\n",
        "  for input_data, taget_data in zip(list_input_data, list_output_data):\n",
        "    regressor = DecisionTreeRegressor(max_depth=None) \n",
        "    regressor.fit(input_data,taget_data)\n",
        "    list_of_all_models.append(regressor)\n",
        "  \n",
        "  \n",
        "  # calculating MSE\n",
        "  predict_y_of_datapoint = np.array(array_of_y)\n",
        "  predict_y_of_datapoint=predict_y_of_datapoint.transpose()\n",
        "  mean_predict_y_of_datapoint = np.mean(predict_y_of_datapoint, axis=1)\n",
        "  mean_predict_y_of_datapoint.shape\n",
        "  MSE = mean_squared_error(y, mean_predict_y_of_datapoint)\n",
        "  \n",
        "  # calculating oob score\n",
        "  predicted_y = []\n",
        "  for i, point in enumerate(x):\n",
        "    model_y_pred = []\n",
        "    for j, model in enumerate(list_of_all_models):\n",
        "      if i not in list_selected_row[j]:\n",
        "        model_y_pred.append(model.predict(point[list_selected_columns[j]].reshape(1,-1)))\n",
        "    predicted_y.append(np.median(np.asarray(model_y_pred)))\n",
        "  OOB_Score = mean_squared_error(y,np.asarray(predicted_y))\n",
        "      \n",
        "    \n",
        "  \n",
        "  return MSE, OOB_Score\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENF9I2s4czJc"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "boston = load_boston()\n",
        "x=boston.data #independent variables \n",
        "y=boston.target #target variable\n",
        "MSE = []\n",
        "OOB_SCORE = []\n",
        "for i in range(0,35):\n",
        "  mse, obb = task2(x,y)\n",
        "  MSE.append(mse)\n",
        "  OOB_SCORE.append(obb)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-BRBSXUqA3l"
      },
      "source": [
        "import scipy\n",
        "confidence_level = 0.95\n",
        "\n",
        "degrees_freedom = 34\n",
        "sample_mean = np.mean(MSE)\n",
        "\n",
        "sample_standard_error = scipy.stats.sem(MSE)\n",
        "\n",
        "\n",
        "confidence_interval = scipy.stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTONPEYmrJFT"
      },
      "source": [
        "sample_mean = np.mean(OOB_SCORE)\n",
        "\n",
        "sample_standard_error = scipy.stats.sem(OOB_SCORE)\n",
        "\n",
        "\n",
        "confidence_interval_ob = scipy.stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxFmwURpqvt0",
        "outputId": "37d71851-7cbe-4261-e15b-68959e795ab7"
      },
      "source": [
        "print(\"CI MSE: \", confidence_interval)\n",
        "print(\"CI OOB: \", confidence_interval_ob )"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CI MSE:  (2.3308125824807377, 2.3308125824807377)\n",
            "CI OOB:  (13.384057246446394, 14.581856304453103)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKTnJdiBVS_e"
      },
      "source": [
        "# <font color='blue'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXxrvZqHV1Fr"
      },
      "source": [
        "<font color='orange'><b>Flowchart for Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyjwEJ62V6a6"
      },
      "source": [
        "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0emSwLL7VurD"
      },
      "source": [
        "![alt text](https://i.imgur.com/Y5cNhQk.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29hjwKlWWDfo"
      },
      "source": [
        "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_pUlSD-VYD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96cea465-114b-4922-d5a4-c3b2b33d21ed"
      },
      "source": [
        "xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60]\n",
        "predicted_y_array = []\n",
        "for i in range(0,30):\n",
        "  \n",
        "  model = list_of_all_models[i]\n",
        "  x_data = [xq[col] for col in list_selected_columns[i]]\n",
        "  x_data = np.array(x_data).reshape(1, -1)\n",
        "  y = model.predict(x_data)\n",
        "  predicted_y_array.append(y)\n",
        "\n",
        "\n",
        "y = np.array(predicted_y_array)\n",
        "predicted_y = np.median(y)\n",
        "print(predicted_y)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJHTGEZgWJjR"
      },
      "source": [
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOdUi-0xWOJ9"
      },
      "source": [
        "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXqwwK-TxAry"
      },
      "source": [
        "## Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4xASHB2xCPZ"
      },
      "source": [
        "## For Task 1 we went through three steps:\n",
        "**Step 1**: We created samples that are randomly generated from the boston datasets. For creating samples first we are going to create the 60% of the random samples of 506 data points and remaining 40% data points will be replicated. We need to take different set of columns for each of the samples, and each samples will have atleast 3 features, columns or attributes.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Step 2**: Now in step 2 we are going to create high variance model on each of the sample for that we are going to create a regression tree with high variance for each of the 30 samples. Now we are going to get the prediction values for each 506 datapoints. Afterwards we will calculate MSE i.e Mean Squared Error value. For calculating MSE we will first get labels by predicting for each model on their specific columns and take the median on predictions.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Step 3**: In this step we are going to calculate the OOB (Out of Bag) score for all 506 for that in oob instead of predicting for all points for each model we will check whether that point is present in the training set of the model, if it is not present then only you will predict using that model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGUzpQ59xfVj"
      },
      "source": [
        "## Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH-5z9OWxNr0"
      },
      "source": [
        "In Task 2 we are going to calculate the Confidence Interval of OOB Score and Train MSE. For that we need to repeat the Task 1 for 35 times and we need to store the Train MSE and OOB score for each iterations. After getting 35 Train MSE and 35 OOB score, using these value we are going to find the Confidence Interval of Train MSE and OOB Score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6T2seX5xbls"
      },
      "source": [
        "## Task 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKCe-o1CxR-l"
      },
      "source": [
        "In Task 3 we need consider a single query point i.e xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] for Predicting the house price for this point as mentioned in the step 2 of Task 1."
      ]
    }
  ]
}